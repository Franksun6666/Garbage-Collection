{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a0c6232-438f-4aef-ad33-608d7d156525",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Garbage Collection\n",
    "**[Wentao Sun](mailto:sunw53@mcmaster.ca), McMaster University, June 2024**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a309cc-931e-4b5c-a204-5b0b00842643",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b96ccc4-b390-4d37-8f87-163acb779202",
   "metadata": {},
   "source": [
    "Manual garbage collection:\n",
    "In C: malloc then free. Basically reserve the memory and you have to free the physical memory at the end of the program in order to avoid resource occupation. Failure to do so might increase the chance of memory leak and eventually run out of available memory. Automatic Memory Management System will work out when finished using memory and give memory back to the OS. That means only malloc is needed without calling free. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7407b89e-1ef2-4cc4-a073-aa7625fa3b5e",
   "metadata": {},
   "source": [
    "Almost all modern programming languages make use of `dynamic memory allocation`. This allows objects to be allocated and deallocated even if their total size was not known at the time that the program was compiled, and if their lifetime may exceed that of the subroutine activation that allocated them. A dynamically allocated object is stored in a heap, rather than on the stack (in the activation record or stack frame of the procedure that allocated it) or statically (whereby the name of an object is bound to a storage location known at compile or link time). \n",
    "\n",
    "Heap allocation is particularly important because it allows the programmer to:\n",
    "\n",
    "    1. choose dynamically the size of new objects (thus avoiding program failure through exceeding hard-coded limits on arrays);\n",
    "    2. deﬁne and use recursive data structures such as lists, trees and maps;\n",
    "    3. return newly created objects to the parent procedure (allowing, for example, factorymethods);\n",
    "    4. return a function as the result of another function (for example, closures or suspensionsin functional languages, or futures or streams in concurrent ones).\n",
    "\n",
    "The goal of an ideal garbage collector is to reclaim the space used by every object that will no longer be used by the program. Any automatic memory management system has three tasks and they're not independent:\n",
    "\n",
    "    1. to allocate space for new objects;\n",
    "    2. to identify live objects as well as dead ones; \n",
    "    3. to reclaim the space occupied by dead objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f4939-0980-4aef-b4cb-b269c552c689",
   "metadata": {},
   "source": [
    "### Some Terminologies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db510e66-49ac-4b5e-aaf2-584bb7cd1979",
   "metadata": {},
   "source": [
    "`Roots:` Typically refer to objects that are directly accessible or referenced by the interpreter, e.g registers, thread stacks, global variables. These objects serve as starting points for the garbage collector to traverse the object graph and determine which objects are reachable and which ones are unreachable for the purpose of memory management. `Any object reference from a variable is a root.`\n",
    "\n",
    "`Dangling references: ` Pointers or references in a program that point to memory locations that have been deallocated, released, or otherwise invalidated. In simpler terms, they are references that are left \"hanging\" without a valid target. \n",
    "\n",
    "Here's 3 possible scenarios:\n",
    "\n",
    "1.Deallocated Memory: If memory allocated for an object is freed or deallocated, but there are still pointers or references pointing to that memory location, those pointers become dangling references.\n",
    "\n",
    "2.Out-of-Scope References: In languages like C or C++, if a pointer to an object is stored in a local variable within a function and that function returns, the local variable goes out of scope, but if the pointer is still accessed or used elsewhere, it becomes a dangling reference because it points to memory that may have been reused for other purposes.\n",
    "\n",
    "3.Object Ownership: In languages without garbage collection, if an object is manually deallocated while other parts of the program still hold references to it, those references become dangling.\n",
    "\n",
    "`Strong Reference:` A strong reference is a direct reference to an object that prevents it from being garbage-collected. As long as there is at least one strong reference to an object, the garbage collector considers it \"alive\" and will not reclaim its memory. Most references in programming are strong references by default. For example, in languages like Java and C#, simply declaring and assigning an object to a variable creates a strong reference. These references ensure that the object remains in memory throughout its use, preventing it from being collected prematurely.\n",
    "\n",
    "`Weak Reference:` A weak reference, on the other hand, does not prevent the garbage collector from reclaiming the object it points to. This means that an object with only weak references is eligible for garbage collection and can be collected at any time when the system runs a garbage collection cycle. Weak references are useful in situations where you need a reference to an object without preventing it from being garbage-collected, which is especially valuable in scenarios involving caching, listeners, or large data structures where memory management is crucial.\n",
    "\n",
    "`Unowned reference`: They are similar to weak references, but they are used when the other instance has the same or longer lifetime. An unowned reference is expected not to become nil once assigned, unlike a weak reference.\n",
    "\n",
    "`Mutators:` These are essentially the application threads that run the main logic of the program. A mutator modifies the heap memory by allocating new objects and potentially making some objects unreachable. The term \"mutator\" is used because these threads mutate the state of the memory, continually changing which objects are accessible and which are not.\n",
    "\n",
    "`Collectors:` These are part of the garbage collection system. A collector's job is to identify memory that is no longer in use and can be reclaimed. The collector operates in its own thread or set of threads separate from those of the application. It scans the memory, marks unused objects, and eventually deallocates or recycles this memory, making it available for future use.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca894bd8-2da8-4149-946a-156bcad38d6f",
   "metadata": {},
   "source": [
    "### 1. Reference Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4a1bbc-90f8-4764-a53e-a645cf74113b",
   "metadata": {},
   "source": [
    "When allocating memory, put a little counter on the object header saying how many parts of the program are still using this. Local variables and formal parameters cause decrements at the end of \n",
    "their lifetime. `Assigning nil causes a decrement.` Reference counting maintains a simple invariant: an object is presumed to be live if and only if the number of references to that object is greater than zero. Reference counting therefore associates a reference count with each object managed; typically this count is stored as an additional slot in the object's header.\n",
    "<img style=\"width:40em;display: block;margin-left: auto;margin-right: auto\" src=\"1.png\"></img> \n",
    "\n",
    "In contrast to the tracing algorithms like mark&sweep, **Algorithm 5.1** redefines all pointer `Read` and `Write` operations in order to manipulate reference counts. Even non-destructive operations such as iteration require the reference counts of each element in the list to be incremented and then decremented as a pointer moves across a data structure such as a list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde6fd86-485c-4ef9-b1f0-5ab916e7434e",
   "metadata": {},
   "source": [
    "#### Algorithm 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0060c6d-4a18-459a-a4ea-dfad7881629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reference:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "\n",
    "def allocate():\n",
    "    # This function would typically allocate a resource or memory\n",
    "    return Reference()\n",
    "\n",
    "def add_reference(ref):\n",
    "    if ref is not None:\n",
    "        ref.count += 1\n",
    "\n",
    "def delete_reference(ref):\n",
    "    if ref is not None:\n",
    "        ref.count -= 1\n",
    "        if ref.count == 0:\n",
    "            free(ref)\n",
    "\n",
    "def free(ref):\n",
    "    # Here you would typically release the allocated resource\n",
    "    print(\"Resource freed.\")\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self.references = []\n",
    "\n",
    "    def new(self):\n",
    "        ref = allocate()\n",
    "        if ref is None:\n",
    "            print(\"Out of memory\")\n",
    "            return None\n",
    "        ref.count = 0\n",
    "        return ref\n",
    "\n",
    "    def write(self, src, i, ref):\n",
    "        add_reference(ref)\n",
    "        if i < len(src) and src[i] is not None:\n",
    "            delete_reference(src[i])\n",
    "        if i >= len(src):\n",
    "            src.append(ref)\n",
    "        else:\n",
    "            src[i] = ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38718fe-1295-4f00-a34d-e0ae49317776",
   "metadata": {},
   "source": [
    "This is a `direct collection method`, direct algorithms determine the liveness of an object from the object alone, without recourse to tracing.\n",
    "\n",
    "This method could have some problems: \n",
    "\n",
    "`1. Add counter and forgot to decrement: ` The most direct consequence of not decrementing a reference count when you should is a memory leak. If a reference count is never decremented properly after the last usage of the object, the counter never reaches zero. This prevents the garbage collector or memory management system from reclaiming the object’s allocated memory, even though it's no longer in use. Over time, these leaks can consume significant amounts of memory, degrading system performance and stability. E.g: Complex Control Flows, Exception Handling, Manual Management.\n",
    "\n",
    "`2. Performance issues: ` From a performance point of view, it is particularly undesirable to add overhead to operations that manipulate registers or thread stack slots. For this reason alone, this naive algorithm is impractical for use as a general purpose, high volume, high performance memory manager.\n",
    "\n",
    "`3. Can’t deal with cycles:` Cycles occur when two or more objects reference each other in a circular manner. In such cases, even though there are no external references to the objects involved in the cycle, their reference counts will never reach zero because they are still referencing each other. Because of this, memory occupied by cyclically referenced objects will never be deallocated using reference counting alone, leading to what's known as a memory leak. <img style=\"width:40em;display: block;margin-left: auto;margin-right: auto\" src=\"2.png\"></img>  \n",
    "\n",
    "Applications of Reference Counting:\n",
    "\n",
    "    better suited for real-time programming;\n",
    "    used in distributed systems, where tracing all pointers is impractical;\n",
    "    used in the Unix file system;\n",
    "    used in the Swift language: strong, weak/unowned references are distinguished\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc30c66-ba4d-4b4b-b97e-5aeb579630ba",
   "metadata": {},
   "source": [
    "#### Swift Code Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ecb89e-eef9-41a3-bc5a-9163143a3123",
   "metadata": {},
   "source": [
    "Here's an example where we have a `Person` class and a `CreditCard` class. A person may or may not have a credit card, and each credit card must be associated with a person. To avoid a retain cycle (where each instance holds a strong reference to the other, preventing both from ever being deallocated), the CreditCard class holds an `unowned reference` to a Person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b2df2f-4320-4635-917e-edc4832b08b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile example.swift\n",
    "class Person {\n",
    "    let name: String\n",
    "    var creditCard: CreditCard?\n",
    "    \n",
    "    init(name: String) {\n",
    "        self.name = name\n",
    "    }\n",
    "    \n",
    "    deinit {\n",
    "        print(\"\\(name) is being deinitialized\")\n",
    "    }\n",
    "}\n",
    "\n",
    "class CreditCard {\n",
    "    let number: UInt64\n",
    "    unowned let owner: Person\n",
    "    \n",
    "    init(number: UInt64, owner: Person) {\n",
    "        self.number = number\n",
    "        self.owner = owner\n",
    "    }\n",
    "    \n",
    "    deinit {\n",
    "        print(\"Card \\(number) is being deinitialized\")\n",
    "    }\n",
    "}\n",
    "\n",
    "// Example usage:\n",
    "var john: Person? = Person(name: \"John Doe\")\n",
    "if let person = john {\n",
    "    john?.creditCard = CreditCard(number: 1234567890123456, owner: person)\n",
    "}\n",
    "\n",
    "// Break the strong reference to see deinitialization in action\n",
    "john = nil  // This should trigger deinitialization of both `Person` and `CreditCard` instances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6baea2-4d54-4abc-a285-0b06b336afc9",
   "metadata": {},
   "source": [
    "In this example:\n",
    "\n",
    "john is a `strong reference` to a new Person instance.\n",
    "Person has an `optional strong reference` to a CreditCard. However, the card has an `unowned reference` back to the person who owns it.\n",
    "Setting john to nil removes the strong reference to the Person instance. Since there are no more strong references to this Person, it is deallocated, and since the CreditCard only holds an `unowned reference` to Person, it is also deallocated. This demonstrates how unowned references help prevent retain cycles without the need for the reference to become nil (which is necessary for weak references)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56533b06-0c3a-4b4e-8ff0-b82a80a33dd1",
   "metadata": {},
   "source": [
    "#### Languages Using Reference Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573bfdde-90cd-4014-b3e7-de5226c36b2d",
   "metadata": {},
   "source": [
    "Several programming languages use reference counting, either as the primary method of memory management or as part of a hybrid system:\n",
    "\n",
    "`Python`: This is perhaps the most well-known language that uses reference counting as a primary mechanism to manage memory. Python complements reference counting with a cyclic garbage collector to deal with reference cycles, which reference counting alone cannot handle.\n",
    "\n",
    "`Objective-C`: Before the adoption of Automatic Reference Counting (ARC), Objective-C used manual reference counting. ARC itself is a form of compiler-enforced reference counting, automating much of the manual counting that was previously required.\n",
    "\n",
    "`Perl`: Perl uses reference counting to manage its memory, cleaning up memory when variables go out of scope and their reference counts fall to zero.\n",
    "\n",
    "`PHP`: PHP uses reference counting to manage memory in its zval (value) data structures, although it also includes a cycle collector to manage reference cycles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d358ee94-8600-4ff2-b863-637073404f93",
   "metadata": {},
   "source": [
    "#### Historical Origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b81efae-8ed1-4819-9e2c-6ab3b80774d6",
   "metadata": {},
   "source": [
    "The concept of reference counting as a form of garbage collection dates back to the early days of computer science. One of the earliest systems to use reference counting was developed by George E. Collins in 1960. However, the technique became more broadly recognized and used after it was described by L. Peter Deutsch and Daniel G. Bobrow in their 1976 paper on reference counting for dynamic storage allocation. (See more in bibliography)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cad4d6-2d78-4541-a88e-7619f76ddcb4",
   "metadata": {},
   "source": [
    "### 2. Deferred Reference Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abf9713-bbfc-4e0a-acad-333e8f12cc7a",
   "metadata": {},
   "source": [
    "Manipulating all reference counts is expensive compared with the cost to the mutator of simple tracing algorithms. Most high-performance reference counting systems use deferred reference counting. The overwhelming majority of pointer loads are to local and temporary variables, that is, to registers or stack slots. A way to reduce this overhead is to keep only an approximate count: pointer stores to local variables do not update the count, `only stores to the heap do`; the count reflects then the number of heap pointers only. The deferred aspect means that updates to the reference count and the associated garbage collection are not performed immediately but are `deferred` to a later time, which can help in optimizing performance especially in `concurrent execution environments`. If the count reaches zero, then the stack has to be scanned to check if local variables are pointing to the object before it can be recycled. This can be deferred by placing objects with zero count in a zero count table first and scanning that table periodically as shown in **Algorithm 5.2**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b0a85c-45e7-4acc-ab9c-149b2de40963",
   "metadata": {},
   "source": [
    "#### Algorithm 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d88761-806a-4c28-b496-38006c0e452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reference:\n",
    "    def __init__(self):\n",
    "        self.count = 0  # Initial reference count is set to zero.\n",
    "\n",
    "def allocate():\n",
    "    return Reference()\n",
    "\n",
    "def add_reference(ref):\n",
    "    if ref is not None:\n",
    "        ref.count += 1\n",
    "\n",
    "def delete_reference_to_zct(ref, zct):\n",
    "        ref.count -= 1\n",
    "        if ref.count == 0:\n",
    "            zct.add(ref)\n",
    "\n",
    "def free(ref):\n",
    "    print(\"Resource freed.\")\n",
    "\n",
    "class ZeroCountTable:\n",
    "    \"\"\"Class to manage the Zero Count Table (ZCT), which tracks objects with zero references.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.items = set()  # Use a set to manage unique items with zero counts.\n",
    "    \n",
    "    def add(self, item):\n",
    "        self.items.add(item)\n",
    "    \n",
    "    def remove(self, item):\n",
    "        self.items.remove(item)\n",
    "    \n",
    "    def is_empty(self):\n",
    "        return len(self.items) == 0\n",
    "\n",
    "    def pop(self):\n",
    "        return self.items.pop()\n",
    "\n",
    "def collect(zct, roots):\n",
    "    \"\"\"Garbage collection process: mark and sweep phase.\"\"\"\n",
    "    for ref in roots:\n",
    "        add_reference(ref)  # Mark\n",
    "    sweep_zct(zct)\n",
    "    for ref in roots:\n",
    "        delete_reference_to_zct(ref, zct)  # Unmark\n",
    "\n",
    "def sweep_zct(zct):\n",
    "    \"\"\"Sweep through the ZCT and free resources with zero effective references.\"\"\"\n",
    "    while not zct.is_empty():\n",
    "        ref = zct.pop()\n",
    "        if ref.count == 0:\n",
    "            free(ref)\n",
    "\n",
    "class Memory:\n",
    "    \"\"\"Simulates memory management with reference counting.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.references = []\n",
    "        self.zct = ZeroCountTable()\n",
    "        self.roots = set()  # Simulating root set\n",
    "\n",
    "    def new(self):\n",
    "        \"\"\"Allocate a new resource and manage out of memory by attempting garbage collection.\"\"\"\n",
    "        ref = allocate()\n",
    "        if ref is None:\n",
    "            collect(self.zct, self.roots)  # Attempt to collect garbage if allocation fails\n",
    "            ref = allocate()\n",
    "            if ref is None:\n",
    "                print(\"Out of memory\")\n",
    "                return None\n",
    "        ref.count = 0\n",
    "        self.zct.add(ref)\n",
    "        return ref\n",
    "\n",
    "    def write(self, src, i, ref):\n",
    "        \"\"\"Write a reference to a source container, managing references appropriately.\"\"\"\n",
    "        if src == self.roots:\n",
    "            src[i] = ref\n",
    "        else:\n",
    "            add_reference(ref)\n",
    "            if i < len(src) and src[i] is not None:\n",
    "                delete_reference_to_zct(src[i], self.zct)\n",
    "            if i >= len(src):\n",
    "                src.append(ref)\n",
    "            else:\n",
    "                src[i] = ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba06f0-4183-40eb-a6b0-44eabca97a12",
   "metadata": {},
   "source": [
    "#### Languages Using Deferred Reference Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1235378e-af26-4677-8b5a-e28634ce9293",
   "metadata": {},
   "source": [
    "Deferred reference counting is used less frequently as a primary memory management technique in mainstream programming languages. However, it has been implemented in various systems and experimental languages, often to optimize performance in specific scenarios:\n",
    "\n",
    "`Python`: Python’s CPython implementation doesn't use deferred reference counting by default, but there have been experimental modifications and proposals to incorporate deferred reference counting to optimize its performance.\n",
    "\n",
    "`Real-Time Systems`: Some real-time programming environments may implement deferred reference counting to reduce the frequency of reference count updates, minimizing the impact on the system's real-time performance.\n",
    "\n",
    "`Research Languages`: Various research-focused programming languages or experimental language extensions have explored deferred reference counting to study its effects on memory management and system performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7e644b-a846-4c76-aced-89b41fda31a0",
   "metadata": {},
   "source": [
    "#### Historical Origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68bc7ab-81fb-4622-84a0-bf231ae48125",
   "metadata": {},
   "source": [
    "The concept of deferred reference counting has been around as a theoretical improvement to standard reference counting since at least the 1980s and 1990s. One key challenge with standard reference counting is the performance cost associated with incrementing and decrementing the reference count each time a reference is made or destroyed. By deferring these updates, a system can potentially batch these operations during less critical times, reducing the immediate computational overhead.\n",
    "\n",
    "Deferred reference counting was discussed in academic papers as a way to optimize garbage collection without the need for a full garbage collector, particularly in systems where consistent performance is critical, such as in embedded or real-time systems. (See more in bibliography)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9655d180-dc7b-4baa-8a80-c22c9e6df55e",
   "metadata": {},
   "source": [
    "### 3. Mark & Sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3d176c-e4ac-40a6-870e-2e7359b69ad9",
   "metadata": {},
   "source": [
    "Garbage collection works in two phases(Mark & Sweep). We assume that each object \n",
    "on the heap has one spare bit for marking and unmarking:\n",
    "\n",
    "`Mark Phase:`\n",
    "The mark phase involves traversing the entire object graph starting from the roots (objects directly accessible by the program) and marking each object encountered as reachable.\n",
    "\n",
    "Objects that are reachable are typically marked using a flag or a bit in their header to indicate that they are still in use.\n",
    "During the traversal, the algorithm follows references from one object to another, marking each object as it encounters them. Such a traversal is called `tracing`.\n",
    "This phase ensures that all objects reachable from the roots are identified and marked as live.\n",
    "\n",
    "`Sweep Phase:`\n",
    "The sweep phase involves traversing the entire heap (memory space allocated for objects) and deallocating memory for objects that are not marked as reachable.\n",
    "The algorithm scans through each memory block, checking whether the corresponding object is marked. If it's marked, it means the object is still in use, so the mark is cleared. If it's not marked, it means the object is no longer reachable and can be safely deallocated.\n",
    "After sweeping through all memory blocks, the algorithm frees the memory associated with unmarked objects, making it available for future allocations.\n",
    "\n",
    "The mark-sweep interface with the mutator is very simple. If a thread is unable to allocate a new object, the collector is called and the allocation request is retried (**Algorithm 2.1**). To emphasize that the collector operates in stop-the-world mode, without concurrent execution of the mutator threads, we mark the collect routine with the `atomic` keyword. If there's still insufficient memory available to meet the allocation request, then heap memory is exhausted. Often this is a fatal error. However, in some languages, New may raise an exception in this circumstance that the programmer may be able to catch. If memory can be released by deleting references (for example, to cached data structures which could be recreated later if necessary), then the allocation request could be repeated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc29a9-a7ba-4bb9-a026-aceee354e815",
   "metadata": {},
   "source": [
    "#### Algorithm 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5c6ba8-1a91-4188-a5d4-ccd19f15019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reference:\n",
    "    \"\"\"Class to simulate an object that can be managed by garbage collection.\"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.marked = False\n",
    "\n",
    "def allocate():\n",
    "    \"\"\"Simulate memory allocation. We limit the number of allocations to simulate a full heap.\"\"\"\n",
    "    if len(heap) < HEAP_LIMIT:\n",
    "        ref = Reference(\"data\")\n",
    "        heap.append(ref)\n",
    "        return ref\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def mark_from_roots(roots):\n",
    "    \"\"\"Mark all reachable objects starting from the root set.\"\"\"\n",
    "    for root in roots:\n",
    "        if not root.marked:\n",
    "            mark(root)\n",
    "\n",
    "def mark(ref):\n",
    "    \"\"\"Recursively mark all references reachable from this reference.\"\"\"\n",
    "    ref.marked = True\n",
    "    for child_ref in ref.data:  # Assuming ref.data contains iterable references\n",
    "        if isinstance(child_ref, Reference) and not child_ref.marked:\n",
    "            mark(child_ref)\n",
    "\n",
    "def sweep(start, end):\n",
    "    \"\"\"Sweep through the heap and free all unmarked objects.\"\"\"\n",
    "    global heap\n",
    "    heap = [ref for ref in heap if ref.marked]\n",
    "    for ref in heap:\n",
    "        ref.marked = False  # Reset the mark for the next GC cycle\n",
    "\n",
    "class MemoryManager:\n",
    "    def __init__(self):\n",
    "        self.roots = set()\n",
    "\n",
    "    def new(self):\n",
    "        \"\"\"Allocate a new reference and perform garbage collection if allocation fails.\"\"\"\n",
    "        ref = allocate()\n",
    "        if ref is null:\n",
    "            self.collect()\n",
    "            ref = allocate()\n",
    "            if ref is null:\n",
    "                raise MemoryError(\"Out of memory\")\n",
    "        return ref\n",
    "\n",
    "    def collect(self):\n",
    "        \"\"\"Perform the mark-and-sweep garbage collection.\"\"\"\n",
    "        mark_from_roots(self.roots)\n",
    "        sweep(0, len(heap))  # Simplified as we're not using actual memory addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddfd8d1-a764-49ac-aa5d-21035574545b",
   "metadata": {},
   "source": [
    "Before traversing the object graph, the collector must first prime the marker's work list with starting points for the traversal (markFromRoots in **Algorithm 2.2**). Each root object is marked and then added to the work list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc264ee-55fe-46d1-89a2-a4c5dfc4140d",
   "metadata": {},
   "source": [
    "#### Algorithm 2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a63651c-0825-4b48-876c-730bafcdda15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.marked = False\n",
    "        self.pointers = []\n",
    "\n",
    "def mark_from_roots(roots):\n",
    "    worklist = []\n",
    "    initialise(worklist)\n",
    "    for root in roots:\n",
    "        if root is not None and not root.marked:\n",
    "            set_marked(root)\n",
    "            worklist.append(root)\n",
    "            mark(worklist)\n",
    "\n",
    "def initialise(worklist):\n",
    "    worklist.clear()\n",
    "\n",
    "def mark(worklist):\n",
    "    while worklist:\n",
    "        ref = worklist.pop(0)  # Assuming remove() takes the first item from the list\n",
    "        for child in ref.pointers:\n",
    "            if child is not None and not child.marked:\n",
    "                set_marked(child)\n",
    "                worklist.append(child)\n",
    "\n",
    "def set_marked(node):\n",
    "    node.marked = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e6dd0b-e82e-4328-99f6-81eb3bf451dc",
   "metadata": {},
   "source": [
    "The sweep phase returns unmarked nodes to the allocator (**Algorithm 2.3**). Typically,the collector sweeps the heap linearly, starting from the bottom, freeing unmarked nodes and resetting the mark bits of marked nodes in preparation for the next collection cycle.Note that we can avoid the cost of resetting the mark bit of live objects if the sense of the bit is switched between one collection and the next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dc2888-1c27-40d7-923d-eb81149cb521",
   "metadata": {},
   "source": [
    "#### Algorithm 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b386e199-1181-4df3-90f1-703103292595",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.marked = False\n",
    "        self.next = None  # Points to the next node in memory, simulating memory layout\n",
    "\n",
    "def sweep(start, end):\n",
    "    scan = start\n",
    "    while scan != end:\n",
    "        if scan.marked:\n",
    "            unset_marked(scan)\n",
    "        else:\n",
    "            free(scan)\n",
    "        scan = next_object(scan)\n",
    "\n",
    "def unset_marked(node):\n",
    "    node.marked = False\n",
    "\n",
    "def free(node):\n",
    "    print(f\"Freeing node: {node}\")\n",
    "\n",
    "def next_object(node):\n",
    "    return node.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bcb82c-68e8-4072-8e48-ea2e5c763181",
   "metadata": {},
   "source": [
    "This is an `indirect collection algorithm`, meaning it doesn't detect garbage per se, but rather identifies all the live objects and then concludes that anything else must be garbage. Note that it needs to recalculate its estimate of the set of live objects at each invocation. Not all garbage collection algorithms behave like this.\n",
    "\n",
    "Its `drawbacks` include fragmentation of memory and pauses during the garbage collection process, which can impact the performance of real-time or interactive applications. Java could left a pointer behind, that pointer could point to millions of other objects, taking up a lot of space. Also for each recursive call, space on the stack for the activation frame is needed. In case we are reclaiming the memory of a singly linked list, that may need more memory space than the list itself!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb164aa6-280c-4317-a98f-89ca59f675d9",
   "metadata": {},
   "source": [
    "#### Languages Using Mark & Sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c76eaf-3770-43f4-b0bd-2bd97f445a4f",
   "metadata": {},
   "source": [
    "Mark and sweep is used either directly or as part of a more complex garbage collection system in several programming languages:\n",
    "\n",
    "`Java`: Java's garbage collection is perhaps the most well-known user of mark and sweep, though it combines this method with others, such as generational and concurrent mark-sweep, in its various garbage collectors like the Concurrent Mark Sweep (CMS) and G1 (Garbage First).\n",
    "\n",
    "`JavaScript`: Modern JavaScript engines like V8 (used in Chrome) and SpiderMonkey (used in Firefox) employ variations of the mark and sweep algorithm, often optimized with techniques like incremental and generational collection to improve performance.\n",
    "\n",
    "`Ruby`: Ruby's garbage collector has also implemented mark and sweep, particularly in its newer versions, to manage memory more efficiently.\n",
    "\n",
    "`Python`: While Python primarily uses reference counting, it also uses a generational garbage collector that employs mark and sweep to deal with cyclic references that reference counting cannot handle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7167588-2edd-4f43-9918-a3d95b954a94",
   "metadata": {},
   "source": [
    "#### Historical Origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c9f8a-1712-42d8-b442-6aa660de192b",
   "metadata": {},
   "source": [
    "The mark and sweep algorithm was first developed and described by John McCarthy around 1960 in connection with the development of the Lisp programming language, which required efficient memory management due to its use of symbolic expressions and frequent object creation. McCarthy's work on Lisp included the development of the first mark and sweep garbage collector to automatically manage memory, a crucial development for the advancement of programming languages that support complex data structures and dynamic memory allocation.\n",
    "\n",
    "Mark and sweep was a significant improvement over earlier manual memory management techniques, where programmers had to explicitly allocate and free memory, a process prone to errors such as memory leaks and dangling pointers. The adoption of mark and sweep and its variations has been central to the development of high-level programming languages that abstract away much of the complexity of memory management, allowing developers to focus more on program logic rather than memory handling. (See more in bibliography)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c30256-7fbf-41ac-869d-a94b20ed1e87",
   "metadata": {},
   "source": [
    "### 4. In-Place Garbage Collection (Deutsch-Schorr-Waite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641b24a8-7d59-47a7-a1d6-3761095246e6",
   "metadata": {},
   "source": [
    "This algorithm is used to modify pointer fields in objects during a `depth-first search`, making it suitable for garbage collection in languages like C and C++ where manual memory management is necessary. It's a non-recursive algorithm that updates the pointer fields during traversal to maintain a link back to the parent object from the current object. This algorithm utilizes two pointers, named `current` and `previous`, to establish these backward links. Each object in this context is structured with two pointer fields and an additional field that records the index (either 0 or 1) of the pointer that points to the parent.\n",
    "<img style=\"width:40em;display: block;margin-left: auto;margin-right: auto\" src=\"3.png\"></img>  \n",
    "<img style=\"width:40em;display: block;margin-left: auto;margin-right: auto\" src=\"4.png\"></img>  \n",
    "\n",
    "One big disadvantage of this algorithm is that it can't run `concurrently` with anything. The DSW algorithm fundamentally modifies the data structures it traverses. It temporarily changes pointers in the data structure to point backwards rather than forwards, thereby eliminating the need for an explicit stack. These modifications mean that the data structure is in a transient, inconsistent state during traversal. Running the DSW algorithm concurrently with other operations that either read or modify the same set of nodes can lead to several concurrency hazards:\n",
    "\n",
    "Race Conditions: If another process is trying to read or modify the data structure while it is being altered by the DSW algorithm, it might encounter incorrect or unexpected pointers, leading to errors or crashes.\n",
    "\n",
    "Deadlocks: Since the DSW algorithm involves complex manipulations of pointers, running it in parallel with other processes that lock the same resources could lead to deadlocks where each process waits for the other to release resources indefinitely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f5373f-4ad3-4c18-94d9-3b51f8ba5f17",
   "metadata": {},
   "source": [
    "`Copying Collection:` The heap is divided into `from-space` and `to-space`. Local and global variables - the roots - point to the from-space:\n",
    "<img style=\"width:40em;display: block;margin-left: auto;margin-right: auto\" src=\"5.png\"></img>  \n",
    "`free` points the next free location; if it reaches `limit`, garbage collection is initiated, copying all reachable objects to the to-space.\n",
    "\n",
    "<img style=\"width:40em;display: block;margin-left: auto;margin-right: auto\" src=\"6.png\"></img> \n",
    "\n",
    "`Advantages` of this Coping Collection:\n",
    "\n",
    "Allocation of new objects only involves incrementing the free pointer; no need to maintain lists of free blocks.\n",
    "\n",
    "Copying collections also performs a compaction; there is no possibility for fragmentation.\n",
    "\n",
    "All reachable objects are copied, but depending on the programming language, many objects are not reachable.\n",
    "\n",
    "`Main Drawback` is that only half of the memory can be used. This can be reduced by dividing the memory into n blocks, selecting one to-space and one from-space among those, and sliding the window. However, objects must be smaller than the block size:\n",
    "\n",
    "<img style=\"width:40em;display: block;margin-left: auto;margin-right: auto\" src=\"7.png\"></img> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc7be3a-ab7a-4dc1-80d0-a35c799fe52d",
   "metadata": {},
   "source": [
    "#### Languages Using In-Place Garbage Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3d03c9-61f2-4e40-835b-bde0b1b88132",
   "metadata": {},
   "source": [
    "While the Deutsch-Schorr-Waite algorithm isn't commonly specified in the documentation of mainstream high-level programming languages' garbage collectors, it is a concept studied in computer science and could be implemented in systems where memory efficiency and the conservation of stack space are particularly crucial:\n",
    "\n",
    "Custom implementations: Systems that require efficient use of memory and stack might implement this algorithm specifically. It's more commonly discussed in academic contexts or in systems programming circles where custom garbage collection strategies are being designed.\n",
    "\n",
    "Educational tools: The algorithm is often implemented in educational settings where the intricacies of garbage collection are taught, helping students understand in-place marking techniques and pointer manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c805f1fa-21da-45f4-9d4c-ab13a81e32d9",
   "metadata": {},
   "source": [
    "#### Historical Origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d6d32b-3414-4637-8a5c-c8ba698a81a0",
   "metadata": {},
   "source": [
    "The Deutsch-Schorr-Waite algorithm was developed by L. Peter Deutsch and Ronald Schorr, and later described by Waite. It's an enhancement of the basic mark and sweep algorithm and was designed to overcome the limitation of excessive stack usage. By modifying the pointers of the objects in the heap itself during the traversal, it avoids the need for a separate stack to track the path during the marking phase of garbage collection. This modification is reversed once the object is processed, returning the pointers to their original state.\n",
    "\n",
    "This algorithm is an excellent example of early innovations in garbage collection techniques that sought to optimize the use of limited computing resources, such as memory and CPU cycles. The Deutsch-Schorr-Waite algorithm showcases how critical efficient garbage collection was, even in the early days of programming, for enabling more complex and resource-intensive applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02574c7-155b-4942-a275-3bb5a4090b75",
   "metadata": {},
   "source": [
    "### 5. Mark-Compact Garbage Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36588c7-3720-4ea5-9a88-976b7455e82c",
   "metadata": {},
   "source": [
    "Mark-compact collection is similar to mark-sweep, but does compaction like copying collection. Initially, starting from the root set, all live objects are `marked`, like in mark-sweep:\n",
    "<img style=\"width:40em;display: block;margin-left: auto;margin-right: auto\" src=\"8.png\"></img> \n",
    "\n",
    "In a `sweep` phase, the new address of each object is calculated and stored it is forwarding field; the new address is the sum of the sizes of all objects encountered so far.\n",
    "<img style=\"width:40em;display: block;margin-left: auto;margin-right: auto\" src=\"9.png\"></img> \n",
    "\n",
    "In the `third` phase, all pointers are updated to point to the new locations.\n",
    "\n",
    "In the `fourth` phase, the objects are moved to their new location; the pointers are left unchanged. On this occasion, all objects are unmarked and all forwarding pointers become unused again:\n",
    "<img style=\"width:15em;display: block;margin-left: auto;margin-right: auto\" src=\"10.png\"></img> \n",
    "\n",
    "`Advantage` of this algorithm:\n",
    "Like copying collection, allocation of new objects only involves incrementing the free pointer; no need to maintain free lists.\n",
    "\n",
    "One extra pointer for forwarding is needed in each object; mark-sweep `does not need extra space`, copying collections needs `twice as much space`(the `from` and `to` space).\n",
    "\n",
    "Like with mark-sweep, the marking phase traverses the whole heap; if it is larger than main memory, swapping occurs. Copying collection only traverses live objects; sometimes only 5% are live.\n",
    "\n",
    "Compaction preserves the original order of objects, unlike copying collection; this supports `locality`(by keeping the original order of objects and reducing the gaps between them, the data structure or memory layout optimizes both spatial and temporal locality) and `better caching`.\n",
    "\n",
    "Mark-compact tends to accumulate long-lived objects at the `bottom of the heap` and would not move them. Copying collections always moves objects, whether small or large.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2514620e-b045-4958-8a90-4d59802a2daa",
   "metadata": {},
   "source": [
    "#### Languages Using Mark-Compact Garbage Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9287765d-c891-4db0-99b9-414a22ef74ed",
   "metadata": {},
   "source": [
    "Several programming languages and runtime environments utilize the mark-compact algorithm, either as a primary method of garbage collection or as one option among several:\n",
    "\n",
    "`Java`: Java's Garbage First (G1) garbage collector, introduced in Java 7, uses a form of mark-compact in certain phases of its operation, particularly during the major collection phase where it compacts the heap to prevent fragmentation.\n",
    "\n",
    "`Haskell`: The Glasgow Haskell Compiler (GHC) uses a generational garbage collector that includes a mark-compact phase to manage the older generation, helping to maintain performance over long-running programs by reducing memory fragmentation.\n",
    "\n",
    "`.NET Framework`: Microsoft's .NET runtime has various garbage collectors, and versions like the server GC can use a mark-compact strategy during full garbage collections to optimize memory usage and access speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4081d46-ce4c-438d-b3e9-87bba83f2440",
   "metadata": {},
   "source": [
    "#### Historical Origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70352a7d-591a-49e0-8169-5d027fe2cbe9",
   "metadata": {},
   "source": [
    "The mark-compact algorithm has its origins in the early days of automated memory management research, emerging as an important technique during the 1960s and 1970s. One of the key motivations for developing this method was to address the fragmentation issues associated with the mark-sweep approach, where memory could become increasingly fragmented over time, leading to inefficient use of space and potential program failure due to insufficient contiguous memory blocks.\n",
    "\n",
    "The development of the mark-compact algorithm is often associated with efforts to optimize garbage collection for systems with limited memory resources where maximizing the utilization of available memory was crucial. Its introduction allowed for more efficient and reliable performance in systems that handle large data or have long runtimes, making it a valuable addition to the repertoire of garbage collection techniques. (See more in bibliography)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecd1665-6689-44c9-a31c-f8cc1791c808",
   "metadata": {},
   "source": [
    "### 6. Generational Garbage Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8d2bc5-88f7-47f1-8bc6-4d5366c437ae",
   "metadata": {},
   "source": [
    "Most objects die shortly after they are created: either an object is created as a \"local\" variable by the program or it's created to store the result of expression evaluation. Almost all objects collected are created since the last collection. `In other words, once an object survives the first collection, it is likely to survive subsequent ones.`\n",
    "\n",
    "Generational collection divides the heap into a number of generations, say an old and a young generation. Different strategies are used for different generations:\n",
    "\n",
    "`A tracing collection like mark-compact is used on the old generation.`\n",
    "\n",
    "`A copying collector is used on the new generation.`\n",
    "\n",
    "Once the heap is full, a minor collection on the youngest generation is performed; if that does not reclaim sufficient memory, the next older generation is collected.\n",
    "<img style=\"width:40em;display: block;margin-left: auto;margin-right: auto\" src=\"15.png\"></img> \n",
    "The young generation is collected by following the pointers from the root set but ignoring those to the old generation.\n",
    "\n",
    "However, pointers from the old generation to the new generation can exist and have to be treated as belonging to the root set. Several options exists:\n",
    "\n",
    "`Remembered set:` whenever a pointer to a new object is stored in an old object, the pointer is added to a remembered set; whenever a new object becomes old, all its pointers to new objects are placed in the remembered set as well.\n",
    "\n",
    "`Card marking:` the heap is divided into cards of equal size and a vector with a bit for every card is maintained. Whenever a pointer is stored in an object, the bit for the location of the pointer is set. A minor collection will check all the marked cards in the old generation. (Used by JDK 1.4.)\n",
    "\n",
    "`Page marking:` if the card size is the page size of the virtual memory, the dirty bit of the page can be used for marking; this assumes that the dirty bit is available to user programs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803aeb9f-e9f5-4f04-a6b4-f6ebc04853d1",
   "metadata": {},
   "source": [
    "#### Languages Using Generational Garbage Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ad2f75-3baf-48f9-b02d-56ca34d2124a",
   "metadata": {},
   "source": [
    "`Java`: Java is one of the most prominent users of generational garbage collection. Java virtual machines (JVMs) typically use a young generation where most new objects are allocated and a copying collector is employed because it's efficient for managing short-lived objects. For the old generation, which houses objects that have survived multiple garbage collection cycles, more thorough methods like mark-compact or mark-sweep are used because these objects are less likely to be garbage and more expensive to collect.\n",
    "\n",
    "`C#/.NET`: .NET uses a similar generational approach in its garbage collector, employing a small-object heap divided into three generations. It uses a combination of mark-and-sweep and compacting strategies, particularly in the older generations.\n",
    "\n",
    "`Python`: Python's CPython implementation uses a form of generational garbage collection alongside reference counting. The collector divides the heap into three generations and primarily uses a mark-sweep algorithm for the older generations.\n",
    "\n",
    "`Ruby`: Ruby also uses generational garbage collection, particularly in the form of its \"RGenGC\" (Ruby Generational Garbage Collector), which was introduced to improve the performance of its previously existing mark-sweep collector by adding generational semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2758fc-e6b3-4289-821d-50f4ea7261bf",
   "metadata": {},
   "source": [
    "#### Historical Origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a64aaa-548f-4f23-b828-e7cea772567a",
   "metadata": {},
   "source": [
    "The concept of generational garbage collection was first formulated and put into practice in the 1980s. One of the seminal works that proposed the use of generational collection was by Lieberman and Hewitt in 1983. They suggested that most objects die young, which was a pivotal observation that led to the development of this technique. The idea was to optimize garbage collection by collecting the young generation more frequently and using faster, less intensive collection methods due to the high mortality rate of young objects, while employing more thorough collection methods for the older generation where objects are less likely to be garbage and more costly in terms of performance to collect.\n",
    "\n",
    "The adoption of generational garbage collection has significantly impacted the development of programming languages and applications, allowing for more efficient memory management, reduced GC pause times, and overall better performance, especially in memory-intensive applications. This method reflects an ongoing evolution in garbage collection technologies, aimed at balancing performance with efficient resource management in complex computing environments. (See more in bibliography)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd16aa6-ea4c-4843-a5af-f48162c7ffe7",
   "metadata": {},
   "source": [
    "### Bibliography\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be481f8-1fb7-448d-b999-e3889586f3f8",
   "metadata": {},
   "source": [
    "<div class=\"csl-bib-body\" style=\"line-height: 1.35; margin-left: 2em; text-indent:-2em;\">\n",
    "<a id='RJ'></a><div class=\"csl-entry\">Richard Jones, Antony Hosking, Eliot Moss. \n",
    "    <i>The Garbage Collection Handbook: The Art of Automatic Memory Management 2nd Edition</i> <a href=\"https://learning.oreilly.com/library/view/the-garbage-collection/9781000883688\">https://learning.oreilly.com/library/view/the-garbage-collection/9781000883688/</a>.</div>\n",
    "<a id='LPD'></a><div class=\"csl-entry\">L. Peter Deutsch and Daniel G. Bobrow.\n",
    "    <i>An Efficient, \n",
    "Incremental, \n",
    "Automatic Garbage \n",
    "Collector</i> <a href=\"https://dl.acm.org/doi/pdf/10.1145/360336.360345\">https://dl.acm.org/doi/pdf/10.1145/360336.360345</a>.</div>\n",
    "<a id='DA'></a><div class=\"csl-entry\">Daniel Anderson, Guy E. Blelloch, Yuanhao Wei.\n",
    "    <i>Concurrent Deferred Reference Counting with\n",
    "Constant-Time Overhead</i> <a href=\"https://dl.acm.org/doi/pdf/10.1145/3453483.3454060\">https://dl.acm.org/doi/pdf/10.1145/3453483.3454060</a>.</div>\n",
    "<a id='DRE'></a><div class=\"csl-entry\">Daniel R. Edelson.\n",
    "    <i>A Mark-and-Sweep Collector for C++</i> <a href=\"https://dl.acm.org/doi/pdf/10.1145/143165.143178\">https://dl.acm.org/doi/pdf/10.1145/143165.143178</a>.</div>\n",
    "<a id='AL'></a><div class=\"csl-entry\">Alexey Loginov, Thomas Reps, and Mooly Sagiv.\n",
    "    <i>Automated Veriﬁcation of the Deutsch-Schorr-WaiteTree-Traversal Algorithm</i> <a href=\"https://www.researchgate.net/publication/221477267_Automated_Verification_of_the_Deutsch-Schorr-Waite_Tree-Traversal_Algorithm\">https://www.researchgate.net/publication/221477267_Automated_Verification_of_the_Deutsch-Schorr-Waite_Tree-Traversal_Algorithm</a>.</div>\n",
    "<a id='SY'></a><div class=\"csl-entry\">Siqiu Yao.\n",
    "    <i>Immix: a Mark-Region Garbage Collector with Space Efficiency, Fast Collection, and Mutator Performance</i> <a href=\"https://www.cs.cornell.edu/courses/cs6120/2019fa/blog/immix/\">https://www.cs.cornell.edu/courses/cs6120/2019fa/blog/immix/</a>.</div>\n",
    "<a id='MJ'></a><div class=\"csl-entry\">MALINA JIANG.\n",
    "    <i>Java Garbage Collection: Analysis of GC Algorithms</i> <a href=\"https://stanford-cs242.github.io/f17/assets/projects/2017/malinaj.pdf\">https://stanford-cs242.github.io/f17/assets/projects/2017/malinaj.pdf</a>.</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
